# ğŸ§  Chat with GPT Streaming

## ğŸ§° Tech Stack

- **FastAPI** â€“ async backend with streaming support
- **Centrifugo** â€“ pub/sub websocket server
- **OpenAI API** â€“ LLM responses (via GPT-3.5/4)
- **httpx** â€“ async publishing to Centrifugo
- **Docker Compose** â€“ one command to run everything

---

## âš™ï¸ Setup

1. Create `.env` file in example root and fill in:

```env
CENTRIFUGO_HTTP_API_KEY="secret"
OPENAI_API_KEY="<YOUR_OPEN_AI_TOKEN>"
```

Then:

```
docker compose up --build
```

Visit: http://localhost:9000
